


# imports
import pandas as pd
import os
import pandas as pd





directory = '../Project_4/Data_Bees/processed_dfs/'
os.makedirs(directory, exist_ok = True)





# Creating the function
def process_data(file): # year data is in the format 2007-08
    
    file = str(file) 
    dfs = [] #store each data frame, for concatenation

    file_for_import = f'../Project_4/Data_Bees/raw_bee_data/{file}.xlsx'
    sheet_names = pd.ExcelFile(file_for_import).sheet_names #see citation
    
    for sheet_name in sheet_names:
        df = pd.read_excel(file_for_import, sheet_name = sheet_name)
        df['year'] = str(sheet_name[0:4]) #make a column for the year
        dfs.append(df) #append df to the list for concatenation

    #concatenate
    df_combo = pd.concat(dfs, ignore_index = True)

    return df_combo

# saving the output df as a variable
colony_loss_df = process_data('BIP Bee Colony Loss Clean')


colony_loss_df.head()


colony_loss_df.info()





cols_to_change = ['Total Winter All Loss', 
                  'Beekeepers Exclusive to State', 
                  'Colonies Exclusive to State', 
                  'year']

def turn_to_float(df):
    for col in cols_to_change:
        if '%' in str(df[col]):
            df[col] = df[col].str.replace('%', '').astype(float)/100
        else:
            df[col] = df[col].astype(float)
    return df

turn_to_float(colony_loss_df)


# saving to .csv
colony_loss_df.to_csv(directory + 'bip_colony_loss_processed.csv')





df_2 = pd.read_csv('./Data_Bees/raw_bee_data/Bee Colony Census data by State.csv')


df_2.describe()


df_2.info()


df_2.isna().sum()





df_2.drop(columns = ['Week Ending', 'Ag District', 'Ag District Code', 'County', 'County ANSI', 'Zip Code', 'Region', 'Domain Category', 'Domain', 'Data Item', 'Commodity', 'watershed_code', 'State ANSI', 'Geo Level', 'Period', 'Program', 'Watershed', 'CV (%)'], inplace = True)


df_2.head()



df_2[df_2['Year'] == 2008]





# The 'value' column in this dataset will be explicitly defined for future merging or concatenation with other dataframes.
df_2['census_value'] = df_2['Value']


# saving to .csv
df_2.to_csv(directory + 'state_census_processed.csv')





df_3 = pd.read_csv('./Data_Bees/raw_bee_data/Bee Colony Survey Data by State.csv')
df_3.head()


df_3.drop(columns = ['CV (%)', 'Watershed', 'Week Ending', 'State ANSI'], inplace = True)


df_3.sort_values(by= ['State'])


df_3.info()





df_3['Value'] = df_3['Value'].str.replace(',', '').astype(int) # needed .str for .replace to work


# I need to combine the periods of months in the 'Period' column to be yearly data
# First, deconstruct the Period Data, into a start and end date, to then use .to_datetime()

def convert_period_to_dates(entry):
    year = entry['Year'] # --> using entry['column'], will make the function go through the rows
    period = entry['Period']

    if 'THRU' in period:
        start_mo, end_mo = period.split('THRU')
        start_date = f'{start_mo} {year}'
        end_date = f'{end_mo} {year}'  
    else:
        start_date = period + f'{year}'
        end_date = period + f'{year}'
        
    return pd.Series([start_date, end_date]) 

# Create two new columsn for start_date and end_date Apply the function to data frame
df_3[['date_start', 'date_end']] = df_3.apply(convert_period_to_dates, axis = 1)

df_3.head()


# dropping the 'period col'
df_3 = df_3.drop(columns = ['Period'])
df_3.head()


df_3.columns





# Group the DataFrame by 'Year', 'State', and 'Data Item', then sum the 'Value' column
df_3 = df_3.groupby(['Year', 'State', 'Data Item'])['Value'].sum().reset_index()


df_3 = df_3[df_3['Data Item'] == 'INVENTORY']
df_3.head()


df_3['State'] = df_3['State'].str.lower()


df_3.drop(columns = ['Data Item'], inplace = True)
df_3.head()


# saving to .csv
df_3.to_csv(directory + 'state_survey_processed.csv')




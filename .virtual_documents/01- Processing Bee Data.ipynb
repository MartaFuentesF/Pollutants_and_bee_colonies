


# imports
import pandas as pd
import os
import pandas as pd





directory = '../Project_4/Data_Bees/processed_dfs/'
os.makedirs(directory, exist_ok = True)





# Creating the function
def process_data(file): # year data is in the format 2007-08
    
    file = str(file) 
    dfs = [] #store each data frame, for concatenation

    file_for_import = f'../Project_4/Data_Bees/{file}.xlsx'
    sheet_names = pd.ExcelFile(file_for_import).sheet_names #see citation
    
    for sheet_name in sheet_names:
        df = pd.read_excel(file_for_import, sheet_name = sheet_name)
        df['year'] = str(sheet_name[0:4]) #make a column for the year
        dfs.append(df) #append df to the list for concatenation

    #concatenate
    df_combo = pd.concat(dfs, ignore_index = True)

    return df_combo

# saving the output df as a variable
colony_loss_df = process_data('BIP Bee Colony Loss Clean')

# saving to .csv
colony_loss_df.to_csv(directory + 'bip_colony_loss_processed.csv')





colony_loss_df.head()


colony_loss_df['year'].describe()


colony_loss_df['year'].sort_values().nunique()


colony_loss_df['year'].sort_values().value_counts()





df_2 = pd.read_csv('./Data_Bees/Bee Colony Census data by State.csv')


df_2.describe()


df_2.info()


df_2.isna().sum()





df_2.drop(columns = ['Week Ending', 'Ag District', 'Ag District Code', 'County', 'County ANSI', 'Zip Code', 'Region', 'Domain Category', 'Domain', 'Data Item', 'Commodity', 'watershed_code', 'State ANSI', 'Geo Level', 'Period', 'Program', 'Watershed', 'CV (%)'], inplace = True)


df_2.head()





# The 'value' column in this dataset will be explicitly defined for future merging or concatenation with other dataframes.
df_2['census_value'] = df_2['Value']


# saving to .csv
df_2.to_csv(directory + 'state_census_processed.csv')






